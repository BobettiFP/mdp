#!/usr/bin/env python3
"""
ë²”ìš© ê°•í™”í•™ìŠµ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
ìë™ìœ¼ë¡œ CSV íŒŒì¼ë“¤ì„ ê°ì§€í•˜ê³  ì»¬ëŸ¼ì„ ë§¤í•‘í•©ë‹ˆë‹¤.
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import argparse
import os
import json
import yaml
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import warnings
warnings.filterwarnings('ignore')

class RLAnalyzer:
    """ê°•í™”í•™ìŠµ ê²°ê³¼ ë¶„ì„ê¸°"""
    
    def __init__(self, config: dict = None):
        self.config = self._load_default_config()
        if config:
            self.config.update(config)
        
        # ì»¬ëŸ¼ ë§¤í•‘ ì„¤ì •
        self.column_mappings = self.config.get('column_mappings', {})
        self.results = {}
        
    def _load_default_config(self) -> dict:
        """ê¸°ë³¸ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        return {
            'file_patterns': ['*.csv'],  # ëª¨ë“  CSV íŒŒì¼
            'column_mappings': {
                'episode': ['episode', 'ep', 'step', 'iteration', 'iter', 'episodes'],
                'reward': ['reward', 'total_reward', 'cumulative_reward', 'return', 'avg_reward'],
                'success': ['success', 'done', 'win', 'complete', 'solved', 'success_rate'],
                'length': ['length', 'steps', 'duration', 'time', 'avg_length'],
                'environment': ['environment', 'env', 'env_type', 'type']
            },
            'success_rate_window': 'auto',  # 'auto' or integer
            'plot_style': 'seaborn',
            'language': 'auto',  # 'auto', 'ko', 'en'
            'output_format': ['plot', 'report', 'summary'],
            'plot_config': {
                'figsize': (15, 10),
                'dpi': 300,
                'style': 'default'  # ë” ì•ˆì „í•œ ê¸°ë³¸ê°’
            }
        }
    
    def auto_detect_columns(self, df: pd.DataFrame) -> Dict[str, str]:
        """ì»¬ëŸ¼ì„ ìë™ìœ¼ë¡œ ê°ì§€í•˜ê³  ë§¤í•‘í•©ë‹ˆë‹¤."""
        detected = {}
        df_columns_lower = [col.lower() for col in df.columns]
        
        for target_col, possible_names in self.column_mappings.items():
            for possible_name in possible_names:
                if possible_name.lower() in df_columns_lower:
                    # ì‹¤ì œ ì»¬ëŸ¼ëª… ì°¾ê¸°
                    actual_col = df.columns[df_columns_lower.index(possible_name.lower())]
                    detected[target_col] = actual_col
                    break
        
        return detected
    
    def calculate_success_rate(self, df: pd.DataFrame, success_col: str) -> pd.Series:
        """ì„±ê³µë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if self.config['success_rate_window'] == 'auto':
            window = max(1, min(100, len(df) // 20))
        else:
            window = self.config['success_rate_window']
        
        return df[success_col].rolling(window=window, min_periods=1).mean()
    
    def load_results(self, log_dir: str) -> Dict[str, pd.DataFrame]:
        """ë¡œê·¸ ë””ë ‰í† ë¦¬ì—ì„œ ê²°ê³¼ íŒŒì¼ë“¤ì„ ìë™ìœ¼ë¡œ ë¡œë“œí•©ë‹ˆë‹¤."""
        results = {}
        log_path = Path(log_dir)
        
        # ëª¨ë“  CSV íŒŒì¼ ì°¾ê¸°
        csv_files = []
        for pattern in self.config['file_patterns']:
            csv_files.extend(log_path.glob(pattern))
        
        print(f"ğŸ” Found {len(csv_files)} CSV files")
        
        for csv_file in csv_files:
            env_type = csv_file.stem
            try:
                df = pd.read_csv(csv_file)
                
                # ì»¬ëŸ¼ ìë™ ê°ì§€
                column_map = self.auto_detect_columns(df)
                
                # íŠ¹ë³„ ì²˜ë¦¬: experiment_summary ê°™ì€ í™˜ê²½ë³„ ìš”ì•½ íŒŒì¼
                if 'environment' in column_map and len(df) <= 10:  # ìš”ì•½ íŒŒì¼ë¡œ ì¶”ì •
                    print(f"ğŸ“‹ {csv_file}: Detected as summary file")
                    # ìš”ì•½ íŒŒì¼ì€ ë³„ë„ ì²˜ë¦¬í•˜ê±°ë‚˜ ìŠ¤í‚µ
                    continue
                
                if not column_map:
                    print(f"âš  {csv_file}: No recognizable columns found")
                    print(f"  Available columns: {list(df.columns)}")
                    # ë‹¤ë¥¸ í˜•íƒœì˜ ì»¬ëŸ¼ë“¤ë„ ì²´í¬
                    if any(col.lower() in ['environment', 'env'] for col in df.columns):
                        print(f"  ğŸ’¡ Looks like a summary file - skipping")
                    continue
                
                # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
                if 'reward' not in column_map:
                    print(f"âš  {csv_file}: No reward column found")
                    continue
                
                # ì»¬ëŸ¼ëª… í‘œì¤€í™”
                renamed_df = df.copy()
                for standard_name, actual_name in column_map.items():
                    if actual_name != standard_name:
                        renamed_df = renamed_df.rename(columns={actual_name: standard_name})
                
                # episode ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìƒì„±
                if 'episode' not in column_map:
                    renamed_df['episode'] = range(1, len(renamed_df) + 1)
                
                # success_rate ê³„ì‚° (success ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
                if 'success' in column_map:
                    renamed_df['success_rate'] = self.calculate_success_rate(
                        renamed_df, 'success'
                    )
                
                results[env_type] = renamed_df
                print(f"âœ” {env_type}: {len(renamed_df)} episodes loaded")
                print(f"  Detected columns: {column_map}")
                
            except Exception as e:
                print(f"âŒ Failed to load {csv_file}: {e}")
        
        self.results = results
        return results
    
    def plot_learning_curves(self, save_path: str = None):
        """í•™ìŠµ ê³¡ì„ ì„ í”Œë¡¯í•©ë‹ˆë‹¤."""
        if not self.results:
            print("No data to plot")
            return
        
        # ë™ì ìœ¼ë¡œ ì„œë¸Œí”Œë¡¯ ê°œìˆ˜ ê²°ì •
        has_success = any('success' in df.columns for df in self.results.values())
        has_length = any('length' in df.columns for df in self.results.values())
        
        subplot_configs = [('reward', 'Reward')]
        if has_success:
            subplot_configs.append(('success_rate', 'Success Rate'))
        if has_length:
            subplot_configs.append(('length', 'Episode Length'))
        
        # ì¶”ê°€ ë¶„ì„
        subplot_configs.append(('reward_dist', 'Reward Distribution'))
        
        n_plots = len(subplot_configs)
        n_cols = 2
        n_rows = (n_plots + 1) // 2
        
        # í”Œë¡¯ ìŠ¤íƒ€ì¼ ì•ˆì „í•˜ê²Œ ì„¤ì •
        try:
            if 'seaborn' in plt.style.available:
                plt.style.use('seaborn-v0_8')
            elif 'ggplot' in plt.style.available:
                plt.style.use('ggplot')
            else:
                plt.style.use('default')
        except:
            plt.style.use('default')
            
        fig, axes = plt.subplots(n_rows, n_cols, 
                                figsize=self.config['plot_config']['figsize'])
        if n_plots == 1:
            axes = [axes]
        elif n_rows == 1:
            axes = [axes]
        else:
            axes = axes.flatten()
        
        fig.suptitle("Learning Analysis", fontsize=16)
        
        for idx, (metric, title) in enumerate(subplot_configs):
            ax = axes[idx]
            
            if metric == 'reward_dist':
                # ë³´ìƒ ë¶„í¬ íˆìŠ¤í† ê·¸ë¨
                for env_type, df in self.results.items():
                    if len(df) >= 2:
                        ax.hist(df['reward'], alpha=0.6, label=env_type, 
                               bins=30, density=True)
                ax.set_xlabel('Reward')
                ax.set_ylabel('Density')
            else:
                # ì‹œê³„ì—´ í”Œë¡¯
                for env_type, df in self.results.items():
                    if len(df) < 2 or metric not in df.columns:
                        continue
                    
                    # ì›ë³¸ ë°ì´í„° (íˆ¬ëª…)
                    ax.plot(df['episode'], df[metric], alpha=0.3, 
                           label=f'{env_type} (raw)')
                    
                    # í‰í™œí™”ëœ ë°ì´í„°
                    window = max(1, len(df) // 50)
                    if window > 1:
                        smoothed = df[metric].rolling(window=window, min_periods=1).mean()
                        ax.plot(df['episode'], smoothed, linewidth=2, 
                               label=f'{env_type} (smooth)')
                
                ax.set_xlabel('Episode')
                ax.set_ylabel(title)
            
            ax.set_title(title)
            ax.legend()
            ax.grid(True, alpha=0.3)
        
        # ë¹ˆ ì„œë¸Œí”Œë¡¯ ìˆ¨ê¸°ê¸°
        for idx in range(len(subplot_configs), len(axes)):
            axes[idx].set_visible(False)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=self.config['plot_config']['dpi'], 
                       bbox_inches='tight')
            print(f"âœ” Plot saved to {save_path}")
        
        plt.show()
    
    def generate_report(self, output_path: str = None) -> str:
        """ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.results:
            return "No data available for analysis"
        
        # ì–¸ì–´ ê°ì§€
        is_korean = any('í•œêµ­' in str(df.columns) for df in self.results.values()) or \
                   self.config['language'] == 'ko'
        
        if is_korean:
            report = self._generate_korean_report()
        else:
            report = self._generate_english_report()
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"âœ” Report saved to {output_path}")
        
        return report
    
    def _generate_english_report(self) -> str:
        """ì˜ì–´ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("# Reinforcement Learning Results Analysis Report\n")
        report.append(f"Generated: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # Summary
        total_episodes = sum(len(df) for df in self.results.values())
        report.append("## Summary\n")
        report.append(f"- Total episodes: {total_episodes:,}")
        report.append(f"- Environments: {len(self.results)}")
        report.append(f"- Analyzed: {', '.join(self.results.keys())}\n")
        
        # Environment analysis
        report.append("## Environment Analysis\n")
        
        for env_type, df in self.results.items():
            if len(df) == 0:
                continue
            
            report.append(f"### {env_type.upper()}\n")
            
            # Basic stats
            reward_stats = df['reward'].describe()
            
            report.append("#### Basic Statistics")
            report.append(f"- Episodes: {len(df):,}")
            report.append(f"- Mean reward: {reward_stats['mean']:.3f}")
            report.append(f"- Reward std: {reward_stats['std']:.3f}")
            report.append(f"- Max reward: {reward_stats['max']:.3f}")
            report.append(f"- Min reward: {reward_stats['min']:.3f}")
            
            if 'success' in df.columns:
                success_rate = df['success'].mean() * 100
                report.append(f"- Success rate: {success_rate:.1f}%")
            
            if 'length' in df.columns:
                length_stats = df['length'].describe()
                report.append(f"- Mean episode length: {length_stats['mean']:.2f}")
            
            report.append("")
        
        return "\n".join(report)
    
    def _generate_korean_report(self) -> str:
        """í•œêµ­ì–´ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = []
        report.append("# ê°•í™”í•™ìŠµ ê²°ê³¼ ë¶„ì„ ë¦¬í¬íŠ¸\n")
        report.append(f"ìƒì„± ì‹œê°„: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        
        # ì „ì²´ ìš”ì•½
        total_episodes = sum(len(df) for df in self.results.values())
        report.append("## ì „ì²´ ìš”ì•½\n")
        report.append(f"- ì´ ì—í”¼ì†Œë“œ ìˆ˜: {total_episodes:,}")
        report.append(f"- í™˜ê²½ ìˆ˜: {len(self.results)}")
        report.append(f"- ë¶„ì„ í™˜ê²½: {', '.join(self.results.keys())}\n")
        
        # í™˜ê²½ë³„ ë¶„ì„
        report.append("## í™˜ê²½ë³„ ë¶„ì„\n")
        
        for env_type, df in self.results.items():
            if len(df) == 0:
                continue
            
            report.append(f"### {env_type.upper()}\n")
            
            # ê¸°ë³¸ í†µê³„
            reward_stats = df['reward'].describe()
            
            report.append("#### ê¸°ë³¸ í†µê³„")
            report.append(f"- ì—í”¼ì†Œë“œ ìˆ˜: {len(df):,}")
            report.append(f"- í‰ê·  ë³´ìƒ: {reward_stats['mean']:.3f}")
            report.append(f"- ë³´ìƒ í‘œì¤€í¸ì°¨: {reward_stats['std']:.3f}")
            report.append(f"- ìµœëŒ€ ë³´ìƒ: {reward_stats['max']:.3f}")
            report.append(f"- ìµœì†Œ ë³´ìƒ: {reward_stats['min']:.3f}")
            
            if 'success' in df.columns:
                success_rate = df['success'].mean() * 100
                report.append(f"- ì„±ê³µë¥ : {success_rate:.1f}%")
            
            if 'length' in df.columns:
                length_stats = df['length'].describe()
                report.append(f"- í‰ê·  ì—í”¼ì†Œë“œ ê¸¸ì´: {length_stats['mean']:.2f}")
            
            report.append("")
        
        return "\n".join(report)
    
    def print_summary(self):
        """ì½˜ì†”ì— ìš”ì•½ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
        if not self.results:
            print("No data available")
            return
        
        print("\n" + "="*60)
        print("ğŸ“Š ANALYSIS SUMMARY")
        print("="*60)
        
        for env_type, df in self.results.items():
            if len(df) > 0:
                avg_reward = df['reward'].mean()
                
                summary_parts = [
                    f"{env_type:>15}: {len(df):>6} episodes",
                    f"avg reward {avg_reward:>6.3f}"
                ]
                
                if 'success' in df.columns:
                    success_rate = df['success'].mean() * 100
                    summary_parts.append(f"success {success_rate:>5.1f}%")
                
                if 'length' in df.columns:
                    avg_length = df['length'].mean()
                    summary_parts.append(f"length {avg_length:>5.1f}")
                
                print(", ".join(summary_parts))

def load_config_file(config_path: str) -> dict:
    """ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    config_path = Path(config_path)
    
    if not config_path.exists():
        return {}
    
    if config_path.suffix.lower() == '.json':
        with open(config_path, 'r') as f:
            return json.load(f)
    elif config_path.suffix.lower() in ['.yaml', '.yml']:
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    else:
        print(f"Unsupported config format: {config_path.suffix}")
        return {}

def main():
    parser = argparse.ArgumentParser(description="ë²”ìš© ê°•í™”í•™ìŠµ ê²°ê³¼ ë¶„ì„ê¸°")
    parser.add_argument("--logdir", default=".", help="ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--output", default="analysis", help="ì¶œë ¥ íŒŒì¼ prefix")
    parser.add_argument("--config", help="ì„¤ì • íŒŒì¼ ê²½ë¡œ (JSON/YAML)")
    parser.add_argument("--no-plot", action="store_true", help="í”Œë¡¯ ìƒì„± ê±´ë„ˆë›°ê¸°")
    parser.add_argument("--pattern", action="append", help="íŒŒì¼ íŒ¨í„´ ì¶”ê°€")
    parser.add_argument("--window", type=int, help="ì„±ê³µë¥  ê³„ì‚° ìœˆë„ìš° í¬ê¸°")
    
    args = parser.parse_args()
    
    # ì„¤ì • ë¡œë“œ
    config = {}
    if args.config:
        config = load_config_file(args.config)
    
    # CLI ì¸ìˆ˜ë¡œ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
    if args.pattern:
        config['file_patterns'] = args.pattern
    if args.window:
        config['success_rate_window'] = args.window
    
    # ë¶„ì„ê¸° ì´ˆê¸°í™”
    analyzer = RLAnalyzer(config)
    
    print(f"ğŸ“Š Analyzing results from {args.logdir}...")
    print(f"ğŸ” File patterns: {analyzer.config['file_patterns']}")
    
    # ê²°ê³¼ ë¡œë“œ
    results = analyzer.load_results(args.logdir)
    
    if not results:
        print("âŒ No analyzable results found!")
        print("ğŸ’¡ Tips:")
        print("  - Check file patterns in config")
        print("  - Ensure CSV files have recognizable column names")
        print("  - Use --pattern to specify custom patterns")
        return
    
    # í”Œë¡¯ ìƒì„±
    if not args.no_plot:
        try:
            analyzer.plot_learning_curves(f"{args.output}_plots.png")
        except ImportError:
            print("âš  matplotlib not available, skipping plots")
        except Exception as e:
            print(f"âš  Plot generation failed: {e}")
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    analyzer.generate_report(f"{args.output}_report.md")
    
    # ìš”ì•½ ì¶œë ¥
    analyzer.print_summary()

if __name__ == "__main__":
    main()