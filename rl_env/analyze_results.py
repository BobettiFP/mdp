#!/usr/bin/env python3
"""
í•™ìŠµ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸
"""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import argparse
import os
from pathlib import Path

def load_results(log_dir: str):
    """ë¡œê·¸ ë””ë ‰í† ë¦¬ì—ì„œ ê²°ê³¼ íŒŒì¼ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    results = {}
    log_path = Path(log_dir)
    
    for csv_file in log_path.glob("*_env.csv"):
        env_type = csv_file.stem.replace("_env", "")
        try:
            df = pd.read_csv(csv_file)
            results[env_type] = df
            print(f"âœ” Loaded {len(df)} episodes from {csv_file}")
        except Exception as e:
            print(f"âŒ Failed to load {csv_file}: {e}")
    
    return results

def plot_learning_curves(results: dict, save_path: str = None):
    """í•™ìŠµ ê³¡ì„ ì„ í”Œë¡¯í•©ë‹ˆë‹¤."""
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle("Learning Curves Comparison", fontsize=16)
    
    for env_type, df in results.items():
        if len(df) < 2:
            continue
            
        # ì´ë™í‰ê·  ê³„ì‚°
        window = min(10, len(df) // 4)  # ì ì‘ì  ìœˆë„ìš° í¬ê¸°
        if window > 0:
            df[f'reward_ma'] = df['reward'].rolling(window=window, min_periods=1).mean()
            df[f'success_ma'] = df['success_rate'].rolling(window=window, min_periods=1).mean()
        else:
            df[f'reward_ma'] = df['reward']
            df[f'success_ma'] = df['success_rate']
    
    # ë³´ìƒ ê³¡ì„ 
    ax = axes[0, 0]
    for env_type, df in results.items():
        if len(df) >= 2:
            ax.plot(df['episode'], df['reward'], alpha=0.3, label=f'{env_type} (raw)')
            ax.plot(df['episode'], df['reward_ma'], linewidth=2, label=f'{env_type} (smooth)')
    ax.set_xlabel('Episode')
    ax.set_ylabel('Reward')
    ax.set_title('Episode Rewards')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # ì„±ê³µë¥  ê³¡ì„ 
    ax = axes[0, 1]
    for env_type, df in results.items():
        if len(df) >= 2:
            ax.plot(df['episode'], df['success_rate'], alpha=0.3, label=f'{env_type} (raw)')
            ax.plot(df['episode'], df['success_ma'], linewidth=2, label=f'{env_type} (smooth)')
    ax.set_xlabel('Episode')
    ax.set_ylabel('Success Rate')
    ax.set_title('Success Rate')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # ë³´ìƒ ë¶„í¬
    ax = axes[1, 0]
    for env_type, df in results.items():
        if len(df) >= 2:
            ax.hist(df['reward'], alpha=0.6, label=env_type, bins=20)
    ax.set_xlabel('Reward')
    ax.set_ylabel('Frequency')
    ax.set_title('Reward Distribution')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # ëˆ„ì  ì„±ê³µë¥ 
    ax = axes[1, 1]
    for env_type, df in results.items():
        if len(df) >= 2:
            cumulative_success = df['success_rate'].expanding().mean()
            ax.plot(df['episode'], cumulative_success, linewidth=2, label=env_type)
    ax.set_xlabel('Episode')
    ax.set_ylabel('Cumulative Success Rate')
    ax.set_title('Cumulative Success Rate')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"âœ” Plot saved to {save_path}")
    
    plt.show()

def generate_report(results: dict, output_path: str = None):
    """ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    report = []
    report.append("# ëŒ€í™” ì‹œìŠ¤í…œ PPO í•™ìŠµ ê²°ê³¼ ë¶„ì„ ë¦¬í¬íŠ¸\n")
    report.append(f"ìƒì„± ì‹œê°„: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # ì „ì²´ ìš”ì•½
    report.append("## ì „ì²´ ìš”ì•½\n")
    total_episodes = sum(len(df) for df in results.values())
    report.append(f"- ì´ ì—í”¼ì†Œë“œ ìˆ˜: {total_episodes:,}")
    report.append(f"- í™˜ê²½ íƒ€ì… ìˆ˜: {len(results)}")
    report.append(f"- ë¶„ì„ëœ í™˜ê²½: {', '.join(results.keys())}\n")
    
    # í™˜ê²½ë³„ ìƒì„¸ ë¶„ì„
    report.append("## í™˜ê²½ë³„ ìƒì„¸ ë¶„ì„\n")
    
    for env_type, df in results.items():
        if len(df) == 0:
            continue
            
        report.append(f"### {env_type.upper()} í™˜ê²½\n")
        
        # ê¸°ë³¸ í†µê³„
        reward_stats = df['reward'].describe()
        success_rate = df['success_rate'].mean() * 100
        
        report.append("#### ê¸°ë³¸ í†µê³„")
        report.append(f"- ì—í”¼ì†Œë“œ ìˆ˜: {len(df):,}")
        report.append(f"- í‰ê·  ë³´ìƒ: {reward_stats['mean']:.3f}")
        report.append(f"- ë³´ìƒ í‘œì¤€í¸ì°¨: {reward_stats['std']:.3f}")
        report.append(f"- ìµœëŒ€ ë³´ìƒ: {reward_stats['max']:.3f}")
        report.append(f"- ìµœì†Œ ë³´ìƒ: {reward_stats['min']:.3f}")
        report.append(f"- ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}%")
        
        # í•™ìŠµ ì§„í–‰ë„ ë¶„ì„
        if len(df) >= 10:
            early_episodes = df.head(len(df)//3)
            late_episodes = df.tail(len(df)//3)
            
            early_reward = early_episodes['reward'].mean()
            late_reward = late_episodes['reward'].mean()
            improvement = late_reward - early_reward
            
            early_success = early_episodes['success_rate'].mean() * 100
            late_success = late_episodes['success_rate'].mean() * 100
            success_improvement = late_success - early_success
            
            report.append(f"\n#### í•™ìŠµ ì§„í–‰ë„")
            report.append(f"- ì´ˆê¸° í‰ê·  ë³´ìƒ: {early_reward:.3f}")
            report.append(f"- í›„ê¸° í‰ê·  ë³´ìƒ: {late_reward:.3f}")
            report.append(f"- ë³´ìƒ ê°œì„ ë„: {improvement:+.3f}")
            report.append(f"- ì´ˆê¸° ì„±ê³µë¥ : {early_success:.1f}%")
            report.append(f"- í›„ê¸° ì„±ê³µë¥ : {late_success:.1f}%")
            report.append(f"- ì„±ê³µë¥  ê°œì„ : {success_improvement:+.1f}%")
        
        report.append("")
    
    # í™˜ê²½ ê°„ ë¹„êµ
    if len(results) >= 2:
        report.append("## í™˜ê²½ ê°„ ë¹„êµ\n")
        
        comparison_data = []
        for env_type, df in results.items():
            if len(df) > 0:
                comparison_data.append({
                    'í™˜ê²½': env_type,
                    'ì—í”¼ì†Œë“œìˆ˜': len(df),
                    'í‰ê· ë³´ìƒ': df['reward'].mean(),
                    'ì„±ê³µë¥ ': df['success_rate'].mean() * 100,
                    'ë³´ìƒë¶„ì‚°': df['reward'].var()
                })
        
        if comparison_data:
            comp_df = pd.DataFrame(comparison_data)
            report.append("| í™˜ê²½ | ì—í”¼ì†Œë“œìˆ˜ | í‰ê· ë³´ìƒ | ì„±ê³µë¥ (%) | ë³´ìƒë¶„ì‚° |")
            report.append("|------|------------|----------|-----------|----------|")
            
            for _, row in comp_df.iterrows():
                report.append(f"| {row['í™˜ê²½']} | {row['ì—í”¼ì†Œë“œìˆ˜']:,} | "
                            f"{row['í‰ê· ë³´ìƒ']:.3f} | {row['ì„±ê³µë¥ ']:.1f} | {row['ë³´ìƒë¶„ì‚°']:.3f} |")
    
    # ê¶Œì¥ì‚¬í•­
    report.append("\n## ê¶Œì¥ì‚¬í•­\n")
    
    best_env = None
    best_performance = -float('inf')
    
    for env_type, df in results.items():
        if len(df) > 0:
            performance = df['reward'].mean() + df['success_rate'].mean()
            if performance > best_performance:
                best_performance = performance
                best_env = env_type
    
    if best_env:
        report.append(f"- **ìµœê³  ì„±ëŠ¥ í™˜ê²½**: {best_env}")
    
    # ì¼ë°˜ì ì¸ ê¶Œì¥ì‚¬í•­
    for env_type, df in results.items():
        if len(df) > 0:
            avg_reward = df['reward'].mean()
            success_rate = df['success_rate'].mean() * 100
            
            if avg_reward < 0.1:
                report.append(f"- {env_type}: ë³´ìƒì´ ë‚®ìŠµë‹ˆë‹¤. ë³´ìƒ í•¨ìˆ˜ë‚˜ í™˜ê²½ ì„¤ì •ì„ ê²€í† í•˜ì„¸ìš”.")
            if success_rate < 10:
                report.append(f"- {env_type}: ì„±ê³µë¥ ì´ ë‚®ìŠµë‹ˆë‹¤. í•™ìŠµ ì‹œê°„ì„ ëŠ˜ë¦¬ê±°ë‚˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì¡°ì •í•˜ì„¸ìš”.")
            if len(df) < 20:
                report.append(f"- {env_type}: ì—í”¼ì†Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë” ê¸´ í•™ìŠµì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    report_text = "\n".join(report)
    
    if output_path:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        print(f"âœ” Report saved to {output_path}")
    
    return report_text

def main():
    parser = argparse.ArgumentParser(description="ë¶„ì„ ëŒ€í™” ì‹œìŠ¤í…œ PPO í•™ìŠµ ê²°ê³¼")
    parser.add_argument("--logdir", default="logs", help="ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ")
    parser.add_argument("--output", default="analysis", help="ì¶œë ¥ íŒŒì¼ prefix")
    parser.add_argument("--no-plot", action="store_true", help="í”Œë¡¯ ìƒì„± ê±´ë„ˆë›°ê¸°")
    
    args = parser.parse_args()
    
    print(f"ğŸ“Š Analyzing results from {args.logdir}...")
    
    # ê²°ê³¼ ë¡œë“œ
    results = load_results(args.logdir)
    
    if not results:
        print("âŒ No results found!")
        return
    
    # í”Œë¡¯ ìƒì„±
    if not args.no_plot:
        try:
            plot_learning_curves(results, f"{args.output}_plots.png")
        except ImportError:
            print("âš  matplotlib not available, skipping plots")
        except Exception as e:
            print(f"âš  Plot generation failed: {e}")
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    report = generate_report(results, f"{args.output}_report.md")
    
    print("\n" + "="*50)
    print("ğŸ“‹ SUMMARY")
    print("="*50)
    
    for env_type, df in results.items():
        if len(df) > 0:
            avg_reward = df['reward'].mean()
            success_rate = df['success_rate'].mean() * 100
            print(f"{env_type:>10}: {len(df):>4} episodes, "
                  f"avg reward {avg_reward:>6.3f}, "
                  f"success rate {success_rate:>5.1f}%")

if __name__ == "__main__":
    main()